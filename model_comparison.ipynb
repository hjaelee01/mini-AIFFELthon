{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9445aa0ccb30448b990bf707cfc5cbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8259c0bc146d4cdab105a3a9c27162bd",
              "IPY_MODEL_7631274374464282ac671cb3ed9bcc9c",
              "IPY_MODEL_3a51b28e9ec149c89685125c60135f3e"
            ],
            "layout": "IPY_MODEL_7a60c79a5dec406abdc981c747044bd0"
          }
        },
        "8259c0bc146d4cdab105a3a9c27162bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43b72a45d0554f93af274c457a41c0cc",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ca04709295483ba16c11fa32bb469f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7631274374464282ac671cb3ed9bcc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4778bce9186c4690b41ca3770cc067db",
            "max": 20689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67f4c24dc95c454bac8ba4fee719b592",
            "value": 20689
          }
        },
        "3a51b28e9ec149c89685125c60135f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a2e180953b84e8f9ef20f04f454582e",
            "placeholder": "​",
            "style": "IPY_MODEL_a8eddc5199af4415a200c9f5884554bb",
            "value": " 20.7k/20.7k [00:00&lt;00:00, 377kB/s]"
          }
        },
        "7a60c79a5dec406abdc981c747044bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b72a45d0554f93af274c457a41c0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ca04709295483ba16c11fa32bb469f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4778bce9186c4690b41ca3770cc067db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f4c24dc95c454bac8ba4fee719b592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a2e180953b84e8f9ef20f04f454582e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8eddc5199af4415a200c9f5884554bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ade096b2e25a4136bc277241c0ac562d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1115d17fb57492eb6b0febecdb283df",
              "IPY_MODEL_cd58265dafe544a9a63c4a3e61a70d60",
              "IPY_MODEL_a5241edb52da4eb7a642933cbd50b00f"
            ],
            "layout": "IPY_MODEL_ed170353ac0142d693c5eb6378e1eb62"
          }
        },
        "b1115d17fb57492eb6b0febecdb283df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1edff8618d4800aebe8c8cf8e0ec22",
            "placeholder": "​",
            "style": "IPY_MODEL_57b36a2e27f143ef98a6677b500620ed",
            "value": "tokenizer.json: 100%"
          }
        },
        "cd58265dafe544a9a63c4a3e61a70d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aa8e0d2f7854833aa1b6eae67f0b16d",
            "max": 2919702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4a0649207fa412a8220c6bb4705d24a",
            "value": 2919702
          }
        },
        "a5241edb52da4eb7a642933cbd50b00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dc5264fc5b74aa8be75249ef8cc8117",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b4514d23694844bb2a479893006c54",
            "value": " 2.92M/2.92M [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "ed170353ac0142d693c5eb6378e1eb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1edff8618d4800aebe8c8cf8e0ec22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b36a2e27f143ef98a6677b500620ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aa8e0d2f7854833aa1b6eae67f0b16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a0649207fa412a8220c6bb4705d24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dc5264fc5b74aa8be75249ef8cc8117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b4514d23694844bb2a479893006c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfab697bdaf0437382993f071ff4a528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a96a726e9a2140d1b1621f1de5c1670c",
              "IPY_MODEL_bbd088e912fb435cb33e91cb80cd9179",
              "IPY_MODEL_122cedc74dd5406a8117481c05926a27"
            ],
            "layout": "IPY_MODEL_e8856f5c92ca4e19aaa9733b3b817835"
          }
        },
        "a96a726e9a2140d1b1621f1de5c1670c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cbcb585935647509a86f79b1a31584b",
            "placeholder": "​",
            "style": "IPY_MODEL_480fa5728ad84ac7b965f19daaf88762",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "bbd088e912fb435cb33e91cb80cd9179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d74115050347e98725c88dbbba8b75",
            "max": 2543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b59268bf2a044dfa928b0cdf62ff141b",
            "value": 2543
          }
        },
        "122cedc74dd5406a8117481c05926a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9492b69dc00847d9ab2c37eba242b15d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d62d03e73dc44c1b8542b6b4b2c829a",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 59.3kB/s]"
          }
        },
        "e8856f5c92ca4e19aaa9733b3b817835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbcb585935647509a86f79b1a31584b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480fa5728ad84ac7b965f19daaf88762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0d74115050347e98725c88dbbba8b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59268bf2a044dfa928b0cdf62ff141b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9492b69dc00847d9ab2c37eba242b15d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d62d03e73dc44c1b8542b6b4b2c829a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55dcb7f7e06949db8eb5c9caaa6b7f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b97f1214a8c246fa9519dc98fdb622a6",
              "IPY_MODEL_f6079be402dd4a1d9d20b8f87170aaf2",
              "IPY_MODEL_1f90fe0f77fc4c9db1bb7db3447ea750"
            ],
            "layout": "IPY_MODEL_29b713e5ab624de99a658b8fc7d9a963"
          }
        },
        "b97f1214a8c246fa9519dc98fdb622a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3edf208684cc47a2a8d78d0f3b5aea16",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0c2bccff7c4d1db8b95fe683a1f7da",
            "value": "config.json: 100%"
          }
        },
        "f6079be402dd4a1d9d20b8f87170aaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd1bf514e044700a1cdc163898eb237",
            "max": 826,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b685f548dac44939c7898d2214854b5",
            "value": 826
          }
        },
        "1f90fe0f77fc4c9db1bb7db3447ea750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b45f55fca834c0f95b203a1fcb4df8c",
            "placeholder": "​",
            "style": "IPY_MODEL_5358fe9c05db410a86689adc12155e07",
            "value": " 826/826 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "29b713e5ab624de99a658b8fc7d9a963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3edf208684cc47a2a8d78d0f3b5aea16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0c2bccff7c4d1db8b95fe683a1f7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd1bf514e044700a1cdc163898eb237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b685f548dac44939c7898d2214854b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b45f55fca834c0f95b203a1fcb4df8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5358fe9c05db410a86689adc12155e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "722161fc77434245ad8e948abd399d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40e16ec1e8d044ada27d82e602656b75",
              "IPY_MODEL_9503d41ba9fd4132bb33168fff922a35",
              "IPY_MODEL_5811c00eff36464f9e0fcad8250f4721"
            ],
            "layout": "IPY_MODEL_a4397e324cba42d48b715faaa9a796e7"
          }
        },
        "40e16ec1e8d044ada27d82e602656b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10ef65851f4b4ee6accf025046d8607d",
            "placeholder": "​",
            "style": "IPY_MODEL_3b5ffb0d38224111a8f2db0f1237eb96",
            "value": "model.safetensors: 100%"
          }
        },
        "9503d41ba9fd4132bb33168fff922a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2d24d6cd814bc3ba384590b21035f9",
            "max": 1102350184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20263c9e5f984f5da6b5682116398fc0",
            "value": 1102350184
          }
        },
        "5811c00eff36464f9e0fcad8250f4721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca65d843d5c4fba8c7489d16c735721",
            "placeholder": "​",
            "style": "IPY_MODEL_e40e55dde78249f6940d01a4d0649320",
            "value": " 1.10G/1.10G [00:18&lt;00:00, 119MB/s]"
          }
        },
        "a4397e324cba42d48b715faaa9a796e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ef65851f4b4ee6accf025046d8607d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b5ffb0d38224111a8f2db0f1237eb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b2d24d6cd814bc3ba384590b21035f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20263c9e5f984f5da6b5682116398fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ca65d843d5c4fba8c7489d16c735721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40e55dde78249f6940d01a4d0649320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5e7c1c3eb0b46f3b30c754f7d4c879d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_032a51ef50e64a8e9d9e159c049316c2",
              "IPY_MODEL_9bda6dbc501b4071a22467aa9bf8831f",
              "IPY_MODEL_89c6df5f4e9842b5a467ed8d2241a6a0"
            ],
            "layout": "IPY_MODEL_70785f61abf94ad99148607ccc6ee633"
          }
        },
        "032a51ef50e64a8e9d9e159c049316c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6970e6806c4861af9209d1d1eb3a00",
            "placeholder": "​",
            "style": "IPY_MODEL_2748e512a46d404c91aea209c233df76",
            "value": "generation_config.json: 100%"
          }
        },
        "9bda6dbc501b4071a22467aa9bf8831f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a35ca88d59084b49ad9363775af4c174",
            "max": 163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47a97d23905f436fb98072548fe316e7",
            "value": 163
          }
        },
        "89c6df5f4e9842b5a467ed8d2241a6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d521dd4f4064e2a97b587ab1abac456",
            "placeholder": "​",
            "style": "IPY_MODEL_2ea8d7fccb094cbba0b26de841ac4a7e",
            "value": " 163/163 [00:00&lt;00:00, 1.75kB/s]"
          }
        },
        "70785f61abf94ad99148607ccc6ee633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6970e6806c4861af9209d1d1eb3a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2748e512a46d404c91aea209c233df76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a35ca88d59084b49ad9363775af4c174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a97d23905f436fb98072548fe316e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d521dd4f4064e2a97b587ab1abac456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea8d7fccb094cbba0b26de841ac4a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2nrVu8p0nQJO",
        "outputId": "f4b567ac-8ec7-400e-96f6-4aec82af0705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.65)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.3.1)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=90fec153bfcd3219f9316c32bf1685b3b7be3d51cb2f920837b25dcf9d266531\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: filetype, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, rouge_score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, google-ai-generativelanguage, evaluate, langchain-google-genai\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed evaluate-0.4.3 filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-dotenv-1.1.0 rouge_score-0.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "cfebd4f7f55349199e45052d7b4b0f67"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install datasets transformers evaluate rouge_score torch accelerate langchain-google-genai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface_hub fsspec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XJxeUYlqaz0",
        "outputId": "0c0f762c-4918-4f1c-fa79-57c3f08d83c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.2)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "# from dotenv import load_dotenv # No longer needed if using Colab Secrets\n",
        "import google.generativeai as genai\n",
        "import datasets\n",
        "import evaluate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "def evaluate_gemini_flash():\n",
        "    \"\"\"\n",
        "    Google Gemini 모델들의 뉴스 요약 성능을 평가하고 ROUGE 점수를 비교합니다.\n",
        "    \"\"\"\n",
        "    # 1. API 키 설정 및 환경 준비\n",
        "    print(\"🔑 Google API 키를 로드합니다...\")\n",
        "    # Load API key from Colab Secrets\n",
        "    google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    if not google_api_key:\n",
        "        print(\"API 키가 설정되지 않았습니다. Colab의 Secrets Manager에 'GOOGLE_API_KEY'를 설정해주세요.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        genai.configure(api_key=google_api_key)\n",
        "    except Exception as e:\n",
        "        print(f\"API 키 설정에 실패했습니다. 오류: {e}\")\n",
        "        return\n",
        "\n",
        "    # The rest of the code remains the same...\n",
        "    # 2. 데이터셋 및 평가 지표 로드\n",
        "    print(\"📦 데이터셋과 ROUGE 평가 지표를 로드합니다...\")\n",
        "    news_dataset = datasets.load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split=\"test\")\n",
        "    rouge = evaluate.load('rouge')\n",
        "\n",
        "    # 🚨 중요: API 호출 비용/사용량 관리를 위해 샘플 수를 조절하세요.\n",
        "    SAMPLE_SIZE = 50\n",
        "    test_samples = news_dataset.select(range(SAMPLE_SIZE))\n",
        "\n",
        "    # 3. Gemini 모델 정의\n",
        "    model_name = \"gemini-1.5-flash-latest\"\n",
        "\n",
        "    results = {}\n",
        "    print(f\"🚀 Gemini 모델 평가를 시작합니다. (샘플 개수: {SAMPLE_SIZE}개)\")\n",
        "\n",
        "    # 4. 요약을 위한 프롬프트 템플릿 정의\n",
        "    prompt_template = \"\"\"\n",
        "    당신은 편견 없이 사실만을 전달하는 전문 뉴스 에디터입니다.\n",
        "    아래 뉴스 기사의 핵심 내용을 원문에 기반하여 3~4개의 문장으로 간결하게 요약해 주세요.\n",
        "    당신의 의견, 추론, 또는 원문에 없는 정보는 절대 포함하지 마세요.\n",
        "\n",
        "    ---\n",
        "    [뉴스 기사]\n",
        "    {article_text}\n",
        "    ---\n",
        "\n",
        "    [요약 결과]\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    output_parser = StrOutputParser()\n",
        "\n",
        "    # 5. 모델별 평가 루프\n",
        "    print(f\"\\n--- 모델 평가 중: {model_name} ---\")\n",
        "    try:\n",
        "        # LangChain을 통해 Gemini 모델 초기화\n",
        "        # Pass google_api_key explicitly to ChatGoogleGenerativeAI\n",
        "        llm = ChatGoogleGenerativeAI(model=model_name, google_api_key=google_api_key, temperature=0.1)\n",
        "        chain = prompt | llm | output_parser\n",
        "    except Exception as e:\n",
        "        print(f\"모델 '{model_name}' 로딩 실패: {e}\\n\")\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "    for i, sample in enumerate(test_samples):\n",
        "        input_text = f\"제목: {sample['title']}\\n\\n본문: {sample['document']}\"\n",
        "        try:\n",
        "            # API 호출로 요약문 생성\n",
        "            generated_summary = chain.invoke({\"article_text\": input_text})\n",
        "            predictions.append(generated_summary)\n",
        "            references.append(sample['summary'])\n",
        "            print(f\"\\r  - 진행률: {i+1}/{SAMPLE_SIZE}\", end=\"\")\n",
        "            # API 과호출 방지를 위한 딜레이 (초당 쿼리 수 제한이 있을 수 있음)\n",
        "            time.sleep(10)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n샘플 {i} 처리 중 API 오류 발생: {e}\")\n",
        "            predictions.append(\"\") # 오류 시 빈 문자열로 처리\n",
        "            references.append(sample['summary'])\n",
        "    print(\"\\n  - ROUGE 점수 계산 중...\")\n",
        "    score = rouge.compute(predictions=predictions, references=references)\n",
        "    results[model_name] = {k: round(v * 100, 2) for k, v in score.items()}\n",
        "    print(f\"  - 계산 완료!\")\n",
        "\n",
        "    # 6. 최종 결과 출력\n",
        "    print(\"\\n--- 📊 최종 평가 결과 (Gemini) ---\")\n",
        "    print(f\"{'모델 이름':<30} | {'ROUGE-1':<10} | {'ROUGE-2':<10} | {'ROUGE-L':<10}\")\n",
        "    print(\"-\" * 70)\n",
        "    for model_name, scores in results.items():\n",
        "        r1 = scores.get('rouge1', 'N/A')\n",
        "        r2 = scores.get('rouge2', 'N/A')\n",
        "        rl = scores.get('rougeL', 'N/A')\n",
        "        print(f\"{model_name:<30} | {r1:<10} | {r2:<10} | {rl:<10}\")\n",
        "\n",
        "    print(\"\\n✅ 평가가 완료되었습니다.\")"
      ],
      "metadata": {
        "id": "88JylRYwKwA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    evaluate_gemini_flash()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zbgmIyKSeL_X",
        "outputId": "e95ab323-0d8c-4758-f944-d360023aaec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Google API 키를 로드합니다...\n",
            "📦 데이터셋과 ROUGE 평가 지표를 로드합니다...\n",
            "🚀 Gemini 모델 평가를 시작합니다. (샘플 개수: 50개)\n",
            "\n",
            "--- 모델 평가 중: gemini-1.5-flash-latest ---\n",
            "  - 진행률: 50/50\n",
            "  - ROUGE 점수 계산 중...\n",
            "  - 계산 완료!\n",
            "\n",
            "--- 모델 평가 중: gemini-1.5-pro-latest ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 3\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 1\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 0 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 1\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 59\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 1 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 59\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 2 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 55\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 3 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 55\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 52\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 4 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 53\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 50\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 5 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 50\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 48\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 6 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 48\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 7 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 44\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 8 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 44\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 42\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 9 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 42\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 40\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 10 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 40\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 38\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 11 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 38\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 36\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 12 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 36\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 34\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 13 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 34\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 32\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 14 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 32\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-77666903>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mevaluate_gemini_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-4284015514>\u001b[0m in \u001b[0;36mevaluate_gemini_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;31m# API 호출로 요약문 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mgenerated_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"article_text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m                 )\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         return cast(\n\u001b[1;32m    371\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    956\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 results.append(\n\u001b[0;32m--> 776\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    777\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         )\n\u001b[0;32m-> 1342\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1343\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_gemini_pro():\n",
        "    \"\"\"\n",
        "    Google Gemini 모델들의 뉴스 요약 성능을 평가하고 ROUGE 점수를 비교합니다.\n",
        "    \"\"\"\n",
        "    # 1. API 키 설정 및 환경 준비\n",
        "    print(\"🔑 Google API 키를 로드합니다...\")\n",
        "    # Load API key from Colab Secrets\n",
        "    google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    if not google_api_key:\n",
        "        print(\"API 키가 설정되지 않았습니다. Colab의 Secrets Manager에 'GOOGLE_API_KEY'를 설정해주세요.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        genai.configure(api_key=google_api_key)\n",
        "    except Exception as e:\n",
        "        print(f\"API 키 설정에 실패했습니다. 오류: {e}\")\n",
        "        return\n",
        "\n",
        "    # The rest of the code remains the same...\n",
        "    # 2. 데이터셋 및 평가 지표 로드\n",
        "    print(\"📦 데이터셋과 ROUGE 평가 지표를 로드합니다...\")\n",
        "    news_dataset = datasets.load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split=\"test\")\n",
        "    rouge = evaluate.load('rouge')\n",
        "\n",
        "    # 🚨 중요: API 호출 비용/사용량 관리를 위해 샘플 수를 조절하세요.\n",
        "    SAMPLE_SIZE = 50\n",
        "    test_samples = news_dataset.select(range(SAMPLE_SIZE))\n",
        "\n",
        "    # 3. Gemini 모델 정의\n",
        "    model_name = \"gemini-1.5-pro-latest\"\n",
        "\n",
        "    results = {}\n",
        "    print(f\"🚀 Gemini 모델 평가를 시작합니다. (샘플 개수: {SAMPLE_SIZE}개)\")\n",
        "\n",
        "    # 4. 요약을 위한 프롬프트 템플릿 정의\n",
        "    prompt_template = \"\"\"\n",
        "    당신은 편견 없이 사실만을 전달하는 전문 뉴스 에디터입니다.\n",
        "    아래 뉴스 기사의 핵심 내용을 원문에 기반하여 3~4개의 문장으로 간결하게 요약해 주세요.\n",
        "    당신의 의견, 추론, 또는 원문에 없는 정보는 절대 포함하지 마세요.\n",
        "\n",
        "    ---\n",
        "    [뉴스 기사]\n",
        "    {article_text}\n",
        "    ---\n",
        "\n",
        "    [요약 결과]\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    output_parser = StrOutputParser()\n",
        "\n",
        "    # 5. 모델별 평가 루프\n",
        "    print(f\"\\n--- 모델 평가 중: {model_name} ---\")\n",
        "    try:\n",
        "        # LangChain을 통해 Gemini 모델 초기화\n",
        "        # Pass google_api_key explicitly to ChatGoogleGenerativeAI\n",
        "        llm = ChatGoogleGenerativeAI(model=model_name, google_api_key=google_api_key, temperature=0.1)\n",
        "        chain = prompt | llm | output_parser\n",
        "    except Exception as e:\n",
        "        print(f\"모델 '{model_name}' 로딩 실패: {e}\\n\")\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "    for i, sample in enumerate(test_samples):\n",
        "        input_text = f\"제목: {sample['title']}\\n\\n본문: {sample['document']}\"\n",
        "        try:\n",
        "            # API 호출로 요약문 생성\n",
        "            generated_summary = chain.invoke({\"article_text\": input_text})\n",
        "            predictions.append(generated_summary)\n",
        "            references.append(sample['summary'])\n",
        "            print(f\"\\r  - 진행률: {i+1}/{SAMPLE_SIZE}\", end=\"\")\n",
        "            # API 과호출 방지를 위한 딜레이 (초당 쿼리 수 제한이 있을 수 있음)\n",
        "            time.sleep(60)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n샘플 {i} 처리 중 API 오류 발생: {e}\")\n",
        "            predictions.append(\"\") # 오류 시 빈 문자열로 처리\n",
        "            references.append(sample['summary'])\n",
        "    print(\"\\n  - ROUGE 점수 계산 중...\")\n",
        "    score = rouge.compute(predictions=predictions, references=references)\n",
        "    results[model_name] = {k: round(v * 100, 2) for k, v in score.items()}\n",
        "    print(f\"  - 계산 완료!\")\n",
        "\n",
        "    # 6. 최종 결과 출력\n",
        "    print(\"\\n--- 📊 최종 평가 결과 (Gemini) ---\")\n",
        "    print(f\"{'모델 이름':<30} | {'ROUGE-1':<10} | {'ROUGE-2':<10} | {'ROUGE-L':<10}\")\n",
        "    print(\"-\" * 70)\n",
        "    for model_name, scores in results.items():\n",
        "        r1 = scores.get('rouge1', 'N/A')\n",
        "        r2 = scores.get('rouge2', 'N/A')\n",
        "        rl = scores.get('rougeL', 'N/A')\n",
        "        print(f\"{model_name:<30} | {r1:<10} | {r2:<10} | {rl:<10}\")\n",
        "\n",
        "    print(\"\\n✅ 평가가 완료되었습니다.\")"
      ],
      "metadata": {
        "id": "IGxFmJUSfjg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_gemini_pro()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N3hmTRkZ9dge",
        "outputId": "909ea854-3f53-4984-86dc-4fb95292b633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Google API 키를 로드합니다...\n",
            "📦 데이터셋과 ROUGE 평가 지표를 로드합니다...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 51\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Gemini 모델 평가를 시작합니다. (샘플 개수: 50개)\n",
            "\n",
            "--- 모델 평가 중: gemini-1.5-pro-latest ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 49\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 0 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 49\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 1 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 47\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 44\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 2 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 44\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 42\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "샘플 3 처리 중 API 오류 발생: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 42\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3290020304>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_gemini_pro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-522909997>\u001b[0m in \u001b[0;36mevaluate_gemini_pro\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# API 호출로 요약문 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mgenerated_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"article_text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m                 )\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         return cast(\n\u001b[1;32m    371\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    956\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 results.append(\n\u001b[0;32m--> 776\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    777\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         )\n\u001b[0;32m-> 1342\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1343\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import datasets\n",
        "import evaluate\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "def evaluate_hf_t5_model():\n",
        "    \"\"\"\n",
        "    HuggingFace의 'Xcz2568/T5-summarization-Korean1' 모델에 대해\n",
        "    뉴스 요약 성능을 평가하고 ROUGE 점수를 계산합니다.\n",
        "    \"\"\"\n",
        "    # 1. 모델 이름 및 환경 설정\n",
        "    model_name = \"Xcz2568/T5-summarization-Korean1\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"🚀 HuggingFace 모델 평가를 시작합니다.\")\n",
        "    print(f\"- 모델: {model_name}\")\n",
        "    print(f\"- 장치: {device}\")\n",
        "\n",
        "    # 2. 데이터셋 및 평가 지표 로드\n",
        "    print(\"📦 데이터셋과 ROUGE 평가 지표를 로드합니다...\")\n",
        "    news_dataset = datasets.load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split=\"test\")\n",
        "    rouge = evaluate.load('rouge')\n",
        "\n",
        "    # 평가할 샘플 수 지정\n",
        "    SAMPLE_SIZE = 50\n",
        "    test_samples = news_dataset.select(range(SAMPLE_SIZE))\n",
        "    print(f\"⚠️ 테스트 샘플 개수: {SAMPLE_SIZE}개\\n\")\n",
        "\n",
        "    # 3. 모델 및 토크나이저 로드\n",
        "    print(f\"--- 모델 로딩 중: {model_name} ---\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "        print(\"✅ 모델 로딩 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"모델 로딩 실패: {e}\\n\")\n",
        "        return\n",
        "\n",
        "    # 4. 모델 평가 루프\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for i, sample in enumerate(test_samples):\n",
        "        # T5 모델은 입력 텍스트 앞에 'summarize: '를 붙여주는 것이 성능에 좋습니다.\n",
        "        input_text = f\"summarize: {sample['title']}. {sample['document']}\"\n",
        "\n",
        "        try:\n",
        "            # 이전 오류들을 해결한 안정적인 요약 생성 방식\n",
        "            # 1. 입력 텍스트를 최대 길이에 맞춰 토큰화 및 절단\n",
        "            inputs = tokenizer(\n",
        "                input_text,\n",
        "                return_tensors=\"pt\",\n",
        "                max_length=1024, # T5 모델에 안전한 최대 길이로 고정\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            # 2. 요약 토큰 생성\n",
        "            summary_ids = model.generate(\n",
        "                inputs['input_ids'],\n",
        "                max_length=128,\n",
        "                min_length=32,\n",
        "                num_beams=4, # Beam search로 더 나은 품질의 결과 생성\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            # 3. 생성된 토큰을 다시 텍스트로 변환\n",
        "            generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "            predictions.append(generated_summary)\n",
        "            references.append(sample['summary'])\n",
        "\n",
        "            print(f\"\\r  - 진행률: {i+1}/{SAMPLE_SIZE}\", end=\"\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n샘플 {i} 처리 중 오류 발생: {e}\")\n",
        "            predictions.append(\"\")\n",
        "            references.append(sample['summary'])\n",
        "\n",
        "    # 5. ROUGE 점수 계산 및 결과 출력\n",
        "    print(\"\\n  - ROUGE 점수 계산 중...\")\n",
        "    score = rouge.compute(predictions=predictions, references=references)\n",
        "    final_result = {k: round(v * 100, 2) for k, v in score.items()}\n",
        "    print(f\"  - 계산 완료!\\n\")\n",
        "\n",
        "    print(f\"--- 📊 최종 평가 결과 ({model_name}) ---\")\n",
        "    print(f\"{'지표':<10} | {'점수':<10}\")\n",
        "    print(\"-\" * 25)\n",
        "    print(f\"{'ROUGE-1':<10} | {final_result.get('rouge1', 'N/A'):<10}\")\n",
        "    print(f\"{'ROUGE-2':<10} | {final_result.get('rouge2', 'N/A'):<10}\")\n",
        "    print(f\"{'ROUGE-L':<10} | {final_result.get('rougeL', 'N/A'):<10}\")\n",
        "\n",
        "    print(\"\\n✅ 평가가 완료되었습니다.\")"
      ],
      "metadata": {
        "id": "S8q8Wz_D9lUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    evaluate_hf_t5_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566,
          "referenced_widgets": [
            "9445aa0ccb30448b990bf707cfc5cbea",
            "8259c0bc146d4cdab105a3a9c27162bd",
            "7631274374464282ac671cb3ed9bcc9c",
            "3a51b28e9ec149c89685125c60135f3e",
            "7a60c79a5dec406abdc981c747044bd0",
            "43b72a45d0554f93af274c457a41c0cc",
            "f6ca04709295483ba16c11fa32bb469f",
            "4778bce9186c4690b41ca3770cc067db",
            "67f4c24dc95c454bac8ba4fee719b592",
            "9a2e180953b84e8f9ef20f04f454582e",
            "a8eddc5199af4415a200c9f5884554bb",
            "ade096b2e25a4136bc277241c0ac562d",
            "b1115d17fb57492eb6b0febecdb283df",
            "cd58265dafe544a9a63c4a3e61a70d60",
            "a5241edb52da4eb7a642933cbd50b00f",
            "ed170353ac0142d693c5eb6378e1eb62",
            "ee1edff8618d4800aebe8c8cf8e0ec22",
            "57b36a2e27f143ef98a6677b500620ed",
            "4aa8e0d2f7854833aa1b6eae67f0b16d",
            "e4a0649207fa412a8220c6bb4705d24a",
            "9dc5264fc5b74aa8be75249ef8cc8117",
            "e5b4514d23694844bb2a479893006c54",
            "cfab697bdaf0437382993f071ff4a528",
            "a96a726e9a2140d1b1621f1de5c1670c",
            "bbd088e912fb435cb33e91cb80cd9179",
            "122cedc74dd5406a8117481c05926a27",
            "e8856f5c92ca4e19aaa9733b3b817835",
            "2cbcb585935647509a86f79b1a31584b",
            "480fa5728ad84ac7b965f19daaf88762",
            "e0d74115050347e98725c88dbbba8b75",
            "b59268bf2a044dfa928b0cdf62ff141b",
            "9492b69dc00847d9ab2c37eba242b15d",
            "0d62d03e73dc44c1b8542b6b4b2c829a",
            "55dcb7f7e06949db8eb5c9caaa6b7f19",
            "b97f1214a8c246fa9519dc98fdb622a6",
            "f6079be402dd4a1d9d20b8f87170aaf2",
            "1f90fe0f77fc4c9db1bb7db3447ea750",
            "29b713e5ab624de99a658b8fc7d9a963",
            "3edf208684cc47a2a8d78d0f3b5aea16",
            "0f0c2bccff7c4d1db8b95fe683a1f7da",
            "7cd1bf514e044700a1cdc163898eb237",
            "6b685f548dac44939c7898d2214854b5",
            "9b45f55fca834c0f95b203a1fcb4df8c",
            "5358fe9c05db410a86689adc12155e07",
            "722161fc77434245ad8e948abd399d62",
            "40e16ec1e8d044ada27d82e602656b75",
            "9503d41ba9fd4132bb33168fff922a35",
            "5811c00eff36464f9e0fcad8250f4721",
            "a4397e324cba42d48b715faaa9a796e7",
            "10ef65851f4b4ee6accf025046d8607d",
            "3b5ffb0d38224111a8f2db0f1237eb96",
            "4b2d24d6cd814bc3ba384590b21035f9",
            "20263c9e5f984f5da6b5682116398fc0",
            "4ca65d843d5c4fba8c7489d16c735721",
            "e40e55dde78249f6940d01a4d0649320",
            "a5e7c1c3eb0b46f3b30c754f7d4c879d",
            "032a51ef50e64a8e9d9e159c049316c2",
            "9bda6dbc501b4071a22467aa9bf8831f",
            "89c6df5f4e9842b5a467ed8d2241a6a0",
            "70785f61abf94ad99148607ccc6ee633",
            "dc6970e6806c4861af9209d1d1eb3a00",
            "2748e512a46d404c91aea209c233df76",
            "a35ca88d59084b49ad9363775af4c174",
            "47a97d23905f436fb98072548fe316e7",
            "9d521dd4f4064e2a97b587ab1abac456",
            "2ea8d7fccb094cbba0b26de841ac4a7e"
          ]
        },
        "id": "BGQZodZQTK6P",
        "outputId": "334cbf45-415c-4718-be2c-a1cf12fee9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 HuggingFace 모델 평가를 시작합니다.\n",
            "- 모델: Xcz2568/T5-summarization-Korean1\n",
            "- 장치: cpu\n",
            "📦 데이터셋과 ROUGE 평가 지표를 로드합니다...\n",
            "⚠️ 테스트 샘플 개수: 50개\n",
            "\n",
            "--- 모델 로딩 중: Xcz2568/T5-summarization-Korean1 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9445aa0ccb30448b990bf707cfc5cbea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ade096b2e25a4136bc277241c0ac562d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfab697bdaf0437382993f071ff4a528"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55dcb7f7e06949db8eb5c9caaa6b7f19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "722161fc77434245ad8e948abd399d62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5e7c1c3eb0b46f3b30c754f7d4c879d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 로딩 완료!\n",
            "  - 진행률: 50/50\n",
            "  - ROUGE 점수 계산 중...\n",
            "  - 계산 완료!\n",
            "\n",
            "--- 📊 최종 평가 결과 (Xcz2568/T5-summarization-Korean1) ---\n",
            "지표         | 점수        \n",
            "-------------------------\n",
            "ROUGE-1    | 22.1      \n",
            "ROUGE-2    | 9.25      \n",
            "ROUGE-L    | 21.3      \n",
            "\n",
            "✅ 평가가 완료되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sq9oGfMmTMF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}